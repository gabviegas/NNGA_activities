{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se2-OL9rlKAZ"
      },
      "source": [
        "# Fera formidável 1: Quem classifica a classe classificadora?\n",
        "\n",
        "**Autores:** Adrian Paz e Gabriel Viégas\n",
        "\n",
        "**Objetivo:**  altere a rede neural feita em Python puro para resolver um problema de classificação. Treine uma rede neural em um dataset simples de classificação para mostrar que funciona.\n",
        "\n",
        "**Comentário:**  aqui é necessário se informar sobre as diferenças de uma rede neural classificadora com relação a uma rede neural regressora. A função de perda, por exemplo, não poderá ser mais a função de perda dos resíduos quadrados.\n",
        "\n",
        "**Comentário 2:**  observe que o enunciado diz claramente que é para realizar a tarefa na rede neural feita em Python puro nos vídeos da disciplina. Se você está usando o ``PyTorch``, ``numpy``, ``tensorflow``, ``keras``, ``lightning`` ou qualquer outra biblioteca pronta, você está no caminho errado!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vFzwiTslV3y"
      },
      "source": [
        "# Resolução:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRhzOy3JBqqy"
      },
      "source": [
        "## Adaptação da rede regressora para a rede classificadora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdiz9FqUBvt9"
      },
      "source": [
        "Nossa resolução foi baseada na aula disponibilizada pelo *Dataquest* no YouTube: [Classification With Neural Networks](https://www.youtube.com/watch?v=71GtdWmznok).\n",
        "\n",
        "Primeiro, realizamos as importações relevantes para a tarefa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cjtbLTn9lFKh"
      },
      "outputs": [],
      "source": [
        "# Importações relevantes\n",
        "import math\n",
        "import random\n",
        "tol = 1e-3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nas redes neurais de classificação binária, a saída deve ser um número entre 0 e 1, de maneira que números mais próximos de 1 vão indicar maior adequação dos dados à classe 1, e vice-versa. O quão próximo de um dos extremos indica a \"certeza\" que a rede neural tem da sua classificação: uma saída de 0.79 representa menos certeza de pertencer à classe 1 que uma saída de 0.99.\n",
        "\n",
        "Para \"forçar\" a saída a apresentar valores entre 0 e 1, é possível usar funções de ativação na última camada oculta que normalizam a saída de maneira que ela assuma valores de 0 a 1. Uma das mais triviais é a função sigmoidal, já vista anteriormente na disciplina, e a escolhida para esse projeto. Para as demais camadas, utilizamos ReLU, uma função comumente utilizada em redes neurais hoje em dia.\n",
        "\n",
        "Assim, assumindo que no tratamento de dados transformaremos os atributos e o *target* em números, a única parte que precisamos mudar na rede neural é a última função de ativação na classe MLP. Abaixo, o trecho de código alterado:\n",
        "\n",
        "```\n",
        "def __call__(self, x, tipo_ativacao='sig'):\n",
        "    for camada in self.camadas[:-1]:\n",
        "        x = camada(x, tipo_ativacao='relu') # transforma x a cada camada chamada\n",
        "        camada_final = self.camadas[-1]\n",
        "        x = camada_final(x, tipo_ativacao)\n",
        "```"
      ],
      "metadata": {
        "id": "A55RvctGmis_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo, as classes necessárias para o funcionamento da rede."
      ],
      "metadata": {
        "id": "GMvww_DQni_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AWuFVAsMM_8y"
      },
      "outputs": [],
      "source": [
        "class Value:\n",
        "    def __init__(self, data, parents=(), parent_operator='', label=''):\n",
        "        if isinstance(data, Value):\n",
        "            self.data = data.data\n",
        "        else:\n",
        "            self.data = data\n",
        "        self.parents = parents\n",
        "        self.parent_operator = parent_operator\n",
        "        self.label = label\n",
        "        self.grad = tol\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Value(data={self.data})\"\n",
        "\n",
        "    def __add__(self, other_value):\n",
        "        \"\"\"self + other_value\"\"\"\n",
        "\n",
        "        if not isinstance(other_value, Value):\n",
        "            other_value = Value(other_value)\n",
        "\n",
        "        parent_operator = \"+\"\n",
        "        parents = (self, other_value)\n",
        "        data = self.data + other_value.data\n",
        "\n",
        "        result = Value(data, parents, parent_operator)\n",
        "\n",
        "        def propagate_add():\n",
        "            self.grad += result.grad * 1 # grad filho * derivada filho em relação a mãe\n",
        "            other_value.grad += result.grad * 1\n",
        "\n",
        "        result.propagate = propagate_add # sobrescreve a função de propagar do vértice filho\n",
        "\n",
        "        return result\n",
        "\n",
        "    def __radd__(self, other_value):\n",
        "        \"\"\"other_value + self\"\"\"\n",
        "\n",
        "        return self + other_value\n",
        "\n",
        "    def __sub__(self, other_value):\n",
        "        \"\"\"self - other_value\"\"\"\n",
        "        return self + (- other_value)\n",
        "\n",
        "    def __rsub__(self, other_value):\n",
        "        return other_value + (-self)\n",
        "\n",
        "    def __mul__(self, other_value):\n",
        "        \"\"\"self * other_val\"\"\"\n",
        "\n",
        "        if not isinstance(other_value, Value):\n",
        "            other_value = Value(other_value)\n",
        "\n",
        "        parent_operator = \"*\"\n",
        "        parents = (self, other_value)\n",
        "        data = self.data * other_value.data\n",
        "\n",
        "        result = Value(data, parents, parent_operator)\n",
        "\n",
        "        def propagate_mul():\n",
        "            self.grad += result.grad * other_value.data # grad filho * derivada filho em rel. mae\n",
        "            other_value.grad += result.grad * self.data\n",
        "\n",
        "        result.propagate = propagate_mul\n",
        "\n",
        "        return result\n",
        "\n",
        "    def __rmul__(self, other_value):\n",
        "        \"\"\"other_val * self\"\"\"\n",
        "        return self * other_value\n",
        "\n",
        "    def __pow__(self, exponential):\n",
        "        \"\"\"self ** expoente\"\"\"\n",
        "\n",
        "        # certificando-se que o expoente é um inteiro ou float\n",
        "        assert isinstance(exponential, (int, float))\n",
        "\n",
        "        parent_operator = f\"**{exponential}\"\n",
        "        parents = (self, )\n",
        "        data = self.data ** exponential\n",
        "\n",
        "        result = Value(data, parents, parent_operator)\n",
        "\n",
        "        def propagate_pow():\n",
        "            self.grad += result.grad * (exponential * self.data ** (exponential - 1))\n",
        "\n",
        "        result.propagate = propagate_pow\n",
        "\n",
        "        return result\n",
        "\n",
        "    def __eq__(self, other_val):\n",
        "        if not isinstance(other_val, Value):\n",
        "          assert isinstance(other_val, (float, int))\n",
        "          other_val = Value(other_val)\n",
        "\n",
        "        return self.data == other_val.data\n",
        "\n",
        "    def __gt__(self, other_val):\n",
        "        if not isinstance(other_val, Value):\n",
        "          assert isinstance(other_val, (float, int))\n",
        "          other_val = Value(other_val)\n",
        "\n",
        "        return self.data > other_val.data\n",
        "\n",
        "    def __lt__(self, other_val):\n",
        "      if not isinstance(other_val, Value):\n",
        "        assert isinstance(other_val, (float, int))\n",
        "        other_val = Value(other_val)\n",
        "\n",
        "      return self.data < other_val.data\n",
        "\n",
        "    def __truediv__(self, other_value):\n",
        "        \"\"\"self / other_value\"\"\"\n",
        "\n",
        "        return self * (other_value ** (-1))\n",
        "\n",
        "    def __rtruediv__(self, other_val):\n",
        "        if not isinstance(other_val, Value):\n",
        "            assert isinstance(other_val, (float, int))\n",
        "            other_val = Value(other_val)\n",
        "\n",
        "        return other_val / self\n",
        "\n",
        "    def __neg__(self):\n",
        "        \"\"\" - self \"\"\"\n",
        "        return self * (-1)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return id(self)\n",
        "\n",
        "    def exp(self, d = None):\n",
        "        \"\"\"exp(self)\"\"\"\n",
        "\n",
        "        parent_operator = \"exp\"\n",
        "        parents = (self,)\n",
        "        data = math.exp(self.data)\n",
        "\n",
        "        result = Value(data, parents, parent_operator)\n",
        "\n",
        "        def propagate_exp():\n",
        "            self.grad += result.grad * data\n",
        "\n",
        "        result.propagate = propagate_exp\n",
        "\n",
        "        return result\n",
        "\n",
        "    def sig(self):\n",
        "        \"\"\"exp(self) / (exp(self) + 1)\"\"\"\n",
        "\n",
        "        return self.exp() / (self.exp() + 1)\n",
        "\n",
        "    def relu(self):\n",
        "        \"\"\"max(0, self)\"\"\"\n",
        "\n",
        "        parent_operator = \"relu\"\n",
        "        parent = (self, )\n",
        "        data = max(0, self.data)\n",
        "        result = Value(data, parent, parent_operator)\n",
        "\n",
        "        def propagate_relu():\n",
        "            self.grad += (1.0 if self.data > 0 else 0.0) * result.grad\n",
        "\n",
        "        result.propagate = propagate_relu\n",
        "        return result\n",
        "\n",
        "    def log(self, base=math.e):\n",
        "        \"\"\"log(self)\"\"\"\n",
        "\n",
        "        # certificando-se que a base é um inteiro ou float positivo\n",
        "        assert isinstance(base, (int, float))\n",
        "        assert base > 0\n",
        "        assert self.data + tol > 0\n",
        "\n",
        "        parent_operator = f\"log{base}\"\n",
        "        parents = (self, )\n",
        "        data = math.log(self.data, base)\n",
        "\n",
        "        result = Value(data, parents, parent_operator)\n",
        "\n",
        "        def propagate_log():\n",
        "            if data == 0:\n",
        "                self.grad = 0\n",
        "            else:\n",
        "                self.grad += result.grad * (1 / self.data * math.log(base + tol)) # gradiente filho * derivada filho em rel. mae\n",
        "\n",
        "        result.propagate = propagate_log\n",
        "\n",
        "        return result\n",
        "\n",
        "    def softplus(self):\n",
        "        \"\"\"ln(1 + exp(self))\"\"\"\n",
        "\n",
        "        return self.log((1 + self.exp()))\n",
        "\n",
        "    def swish(self, beta=1):\n",
        "        \"\"\"self * (1 + exp(-beta * self))^-1\"\"\"\n",
        "\n",
        "        assert isinstance(beta, (int, float))\n",
        "\n",
        "        return self * (1 + (1 / self.exp(((-beta) * self.data))))\n",
        "\n",
        "    def propagate(self):\n",
        "        pass\n",
        "\n",
        "    def propagate_all(self):\n",
        "        \"\"\"Propagação que só pode ser feita a partir do vértice folha.\"\"\"\n",
        "        self.grad = 1\n",
        "\n",
        "        # Busca em profundidade\n",
        "        topological_order = []\n",
        "        visited = set()\n",
        "        def build_top_order(v):\n",
        "          if v not in visited:\n",
        "            visited.add(v)\n",
        "            for parent in v.parents:\n",
        "              build_top_order(parent)\n",
        "              topological_order.append(v)\n",
        "\n",
        "        build_top_order(self)\n",
        "\n",
        "        for v in reversed(topological_order):\n",
        "            v.propagate()\n",
        "\n",
        "class Neuronio:\n",
        "    def __init__(self, num_dados_entrada):\n",
        "        self.vies = Value(random.uniform(-1,1))\n",
        "\n",
        "        self.pesos = []\n",
        "        for _ in range(num_dados_entrada):\n",
        "            self.pesos.append(Value(random.uniform(-1,1)))\n",
        "\n",
        "    def __call__(self, x, tipo_ativacao='sig'):\n",
        "        # calcula o dado de saída\n",
        "\n",
        "        assert len(x) == len(self.pesos) # evita erros posteriores\n",
        "\n",
        "        soma = 0\n",
        "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
        "            soma += info_entrada * peso_interno\n",
        "\n",
        "        soma += self.vies\n",
        "\n",
        "        if tipo_ativacao == 'sig':\n",
        "            dado_de_saida = soma.sig()\n",
        "        elif tipo_ativacao == 'relu':\n",
        "            dado_de_saida = soma.relu()\n",
        "        elif tipo_ativacao == 'softplus':\n",
        "            dado_de_saida = soma.softplus()\n",
        "        elif tipo_ativacao == 'swish':\n",
        "            dado_de_saida = soma.swish()\n",
        "        else:\n",
        "            dado_de_saida = soma\n",
        "\n",
        "        return dado_de_saida\n",
        "\n",
        "    def parametros(self):\n",
        "        return self.pesos + [self.vies]\n",
        "\n",
        "class Camada:\n",
        "    def __init__(self, num_neuronios, num_dados_entrada):\n",
        "        neuronios = []\n",
        "\n",
        "        for _ in range(num_neuronios):\n",
        "            neuronio = Neuronio(num_dados_entrada)\n",
        "            neuronios.append(neuronio)\n",
        "\n",
        "        self.neuronios = neuronios\n",
        "\n",
        "    def __call__(self, x, tipo_ativacao='sig'):\n",
        "        dados_de_saida = []\n",
        "\n",
        "        for neuronio in self.neuronios:\n",
        "            informacao = neuronio(x, tipo_ativacao)\n",
        "            dados_de_saida.append(informacao)\n",
        "\n",
        "        if len(dados_de_saida) == 1:\n",
        "            return dados_de_saida[0] # garante que o valor retornado seja um número caso estejamos na output layer\n",
        "        else:\n",
        "            return dados_de_saida # para hidden layers\n",
        "\n",
        "    def parametros(self):\n",
        "        params = []\n",
        "\n",
        "        for neuronio in self.neuronios:\n",
        "            params_neuronio = neuronio.parametros()\n",
        "            params.extend(params_neuronio) # concatena listas\n",
        "\n",
        "        return params\n",
        "\n",
        "class MLP_classificadora:\n",
        "    def __init__(self, num_dados_entrada: int, num_neuronios_por_camada: list):\n",
        "\n",
        "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
        "        camadas = []\n",
        "\n",
        "        # estamos criando apenas a partir da primeira camada escondida\n",
        "        for i in range(len(num_neuronios_por_camada)):\n",
        "            camada = Camada(num_neuronios_por_camada[i], percurso[i])\n",
        "            camadas.append(camada)\n",
        "\n",
        "        self.camadas = camadas\n",
        "\n",
        "    def __call__(self, x, tipo_ativacao='sig'):\n",
        "\n",
        "        for camada in self.camadas[:-1]:\n",
        "            x = camada(x, tipo_ativacao='relu') # transforma x a cada camada chamada\n",
        "\n",
        "        camada_final = self.camadas[-1]\n",
        "        x = camada_final(x, tipo_ativacao='sig')\n",
        "\n",
        "        return x # retorna apenas um valor, representando apenas o output\n",
        "\n",
        "    def parametros(self):\n",
        "        params = []\n",
        "\n",
        "        for camada in self.camadas:\n",
        "            params_camada = camada.parametros()\n",
        "            params.extend(params_camada) # concatena listas\n",
        "\n",
        "        return params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicando dados sintéticos na rede neural"
      ],
      "metadata": {
        "id": "C_lBzntFIDD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Geração de dados a partir do `scikit-learn`\n",
        "\n"
      ],
      "metadata": {
        "id": "YpnMvVskILg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de aplicar em dados reais, vamos gerar um pequeno conjunto de dados e verificar o comportamento de nossa rede neural de classificação. Utilizaremos o método `make_classification` da biblioteca `sklearn.datasets` para gerar um pequeno conjunto de dados com poucos atributos rastreáveis."
      ],
      "metadata": {
        "id": "Us1HU2joIOut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# faz um dataset sintético com 2 atributos relevantes e 2 classes\n",
        "X, Y = make_classification(n_samples=10, n_features=2, n_redundant=0, random_state=2410, n_informative=2, n_clusters_per_class=1, n_classes=2)\n",
        "\n",
        "# plota a distribuição das classes\n",
        "plt.scatter(X[:, 0], X[:, 1], c=Y)\n",
        "plt.colorbar()\n",
        "plt.title('Distribuição dos dados sintéticos com seus atributos relevantes pelas classes 0 e 1');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "efl2i7uUID8m",
        "outputId": "1c3d77cc-4156-4360-c09d-821c6fbfa99c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento da rede neural com dados sintéticos"
      ],
      "metadata": {
        "id": "gJ3mD9BoIT0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_DADOS_DE_ENTRADA = 2\n",
        "NUM_DADOS_DE_SAIDA = 1\n",
        "CAMADAS_OCULTAS = [3, 2]\n",
        "\n",
        "arquitetura_da_rede = CAMADAS_OCULTAS + [NUM_DADOS_DE_SAIDA]\n",
        "\n",
        "minha_mlp = MLP_classificadora(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede)"
      ],
      "metadata": {
        "id": "CLi4feweIXZc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCAS = 20\n",
        "TAXA_DE_APRENDIZADO = 0.000001\n",
        "\n",
        "for epoca in range(NUM_EPOCAS):\n",
        "\n",
        "    # forward pass\n",
        "    y_pred = []\n",
        "\n",
        "    for exemplo in X:\n",
        "        previsao = minha_mlp(exemplo)\n",
        "        y_pred.append(previsao)\n",
        "\n",
        "    # loss\n",
        "    erros = []\n",
        "    for yt, yp in zip(Y, y_pred):\n",
        "        yt = Value(yt)\n",
        "        nll = -(yt * (yp + tol).log() + (1 - yt) * (1 - yp + tol).log())\n",
        "        erros.append(nll)\n",
        "\n",
        "    loss = sum(erros) / len(erros)\n",
        "\n",
        "    # zero grad\n",
        "    parametros_antes = minha_mlp.parametros()\n",
        "    for p in minha_mlp.parametros():\n",
        "        p.grad = 0\n",
        "\n",
        "    # backpropagation\n",
        "    loss.propagate_all()\n",
        "\n",
        "    # atualiza parâmetros\n",
        "    for p in minha_mlp.parametros():\n",
        "        p.data = p.data - p.grad * TAXA_DE_APRENDIZADO\n",
        "\n",
        "    # mostra resultado (opcional)\n",
        "    print(epoca, loss.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJUTL6wIIcsL",
        "outputId": "5c6caed4-7d6f-4c85-9e8f-c6535318db21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7048716966727403\n",
            "1 0.7039895829167465\n",
            "2 0.7031975859076938\n",
            "3 0.7024758163121239\n",
            "4 0.7018115576144592\n",
            "5 0.7011961348767275\n",
            "6 0.7006232602058221\n",
            "7 0.7000881215121957\n",
            "8 0.6995868571965989\n",
            "9 0.6988204679541078\n",
            "10 0.6962787856868401\n",
            "11 0.6938865451697724\n",
            "12 0.6915795963715781\n",
            "13 0.6893140327621022\n",
            "14 0.6870607285352122\n",
            "15 0.6848020291202709\n",
            "16 0.6825295348597378\n",
            "17 0.6817779227497028\n",
            "18 0.6796050944665393\n",
            "19 0.6777525034500029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Percebe-se uma redução pequena do valor da perda, que pode ser atribuído a alguma sensibilidade do valor inicial dos parâmetros que não está sendo capturada aqui."
      ],
      "metadata": {
        "id": "gWDgzEgjJKL4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJMNk6JxBlRe"
      },
      "source": [
        "## Aplicando dados reais na rede neural"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratamento dos dados"
      ],
      "metadata": {
        "id": "IZg7CpWkmviq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1lTaXEblCLxS"
      },
      "outputs": [],
      "source": [
        "# importações relevantes para essa parte\n",
        "import pandas as pd\n",
        "#from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MaxAbsScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whYk2r7Tmva_"
      },
      "source": [
        "Definimos que nosso *dataset* seria o \"Occupancy Detection\", retirado do [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/357/occupancy+detection). As colunas são todas numéricas, não apresentam dados faltantes, e são as seguintes:\n",
        "\n",
        "- Data da medição\n",
        "- Temperatura (ºC) da sala\n",
        "- Umidade percentual (%) da sala\n",
        "- Luz (Lux)\n",
        "- Quantidade de $CO_2$ (ppm) na sala\n",
        "- Umidade específica ($\\frac{kg_{vapor-de-água}}{kg_{ar}}$) da sala, que mede a quantidade de vapor de água dada uma massa de ar seco.\n",
        "- Ocupação da sala, em que 0 significa que não está ocupada, e 1 que está.\n",
        "\n",
        "Dentre as colunas, para evitar trabalhar com séries temporais e entendendo que só precisamos de uma das informações de umidade, escolhemos como atributos: Temperatura; Luz; Quantidade de $CO_2$; e Umidade específica. Nosso *target* será a ocupação da sala.\n",
        "\n",
        "Abaixo, verificamos o começo do *DataFrame*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BQN4dzK6mYRy",
        "outputId": "7b229b87-1b0d-4e60-fb01-2a7f20e4bbde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   date  Temperature   Humidity  Light          CO2  \\\n",
              "0   2015-02-13 18:47:00       21.230  32.433333    0.0   534.750000   \n",
              "1   2015-02-07 00:11:59       20.000  18.790000    0.0   438.000000   \n",
              "2   2015-02-10 01:52:00       20.290  32.900000    0.0   461.000000   \n",
              "3   2015-02-17 12:23:59       21.700  32.730000  464.0  1286.333333   \n",
              "4   2015-02-15 10:23:00       21.890  29.000000  289.0   639.000000   \n",
              "..                  ...          ...        ...    ...          ...   \n",
              "95  2015-02-05 21:47:00       20.745  20.390000    0.0   458.500000   \n",
              "96  2015-02-05 16:53:00       22.290  25.700000  441.0  1045.666667   \n",
              "97  2015-02-16 15:42:59       21.865  28.972500  449.0   895.000000   \n",
              "98  2015-02-05 07:34:59       20.700  22.390000    0.0   449.000000   \n",
              "99  2015-02-17 08:44:00       20.600  30.745000  419.0   818.500000   \n",
              "\n",
              "    HumidityRatio  Occupancy  \n",
              "0        0.005064          0  \n",
              "1        0.002709          0  \n",
              "2        0.004846          0  \n",
              "3        0.005261          1  \n",
              "4        0.004712          0  \n",
              "..            ...        ...  \n",
              "95       0.003080          0  \n",
              "96       0.004276          1  \n",
              "97       0.004700          1  \n",
              "98       0.003375          0  \n",
              "99       0.004615          1  \n",
              "\n",
              "[100 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6a8c483-9f56-4e31-86bc-49cd337a5ffe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Light</th>\n",
              "      <th>CO2</th>\n",
              "      <th>HumidityRatio</th>\n",
              "      <th>Occupancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-02-13 18:47:00</td>\n",
              "      <td>21.230</td>\n",
              "      <td>32.433333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>534.750000</td>\n",
              "      <td>0.005064</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-02-07 00:11:59</td>\n",
              "      <td>20.000</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>438.000000</td>\n",
              "      <td>0.002709</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-02-10 01:52:00</td>\n",
              "      <td>20.290</td>\n",
              "      <td>32.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>461.000000</td>\n",
              "      <td>0.004846</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-02-17 12:23:59</td>\n",
              "      <td>21.700</td>\n",
              "      <td>32.730000</td>\n",
              "      <td>464.0</td>\n",
              "      <td>1286.333333</td>\n",
              "      <td>0.005261</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-02-15 10:23:00</td>\n",
              "      <td>21.890</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>289.0</td>\n",
              "      <td>639.000000</td>\n",
              "      <td>0.004712</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>2015-02-05 21:47:00</td>\n",
              "      <td>20.745</td>\n",
              "      <td>20.390000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>458.500000</td>\n",
              "      <td>0.003080</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2015-02-05 16:53:00</td>\n",
              "      <td>22.290</td>\n",
              "      <td>25.700000</td>\n",
              "      <td>441.0</td>\n",
              "      <td>1045.666667</td>\n",
              "      <td>0.004276</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2015-02-16 15:42:59</td>\n",
              "      <td>21.865</td>\n",
              "      <td>28.972500</td>\n",
              "      <td>449.0</td>\n",
              "      <td>895.000000</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2015-02-05 07:34:59</td>\n",
              "      <td>20.700</td>\n",
              "      <td>22.390000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>449.000000</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2015-02-17 08:44:00</td>\n",
              "      <td>20.600</td>\n",
              "      <td>30.745000</td>\n",
              "      <td>419.0</td>\n",
              "      <td>818.500000</td>\n",
              "      <td>0.004615</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6a8c483-9f56-4e31-86bc-49cd337a5ffe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6a8c483-9f56-4e31-86bc-49cd337a5ffe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6a8c483-9f56-4e31-86bc-49cd337a5ffe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7d7cc38b-f11b-474b-bb43-17db41cf93fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d7cc38b-f11b-474b-bb43-17db41cf93fd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7d7cc38b-f11b-474b-bb43-17db41cf93fd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_18343c9e-6f68-4da7-a1dd-03c51ef78a38\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_18343c9e-6f68-4da7-a1dd-03c51ef78a38 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"2015-02-17 22:40:59\",\n          \"2015-02-05 16:05:00\",\n          \"2015-02-14 19:25:59\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2050283838999367,\n        \"min\": 19.2,\n        \"max\": 24.39,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          22.9725,\n          21.5666666666667,\n          21.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Humidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.142187914547243,\n        \"min\": 17.39,\n        \"max\": 39.4,\n        \"num_unique_values\": 85,\n        \"samples\": [\n          25.2,\n          32.4333333333333,\n          25.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Light\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 231.75582149289667,\n        \"min\": 0.0,\n        \"max\": 799.0,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          449.0,\n          149.5,\n          658.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 346.036731366562,\n        \"min\": 422.0,\n        \"max\": 1779.0,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          1509.75,\n          767.0,\n          1342.66666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HumidityRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007661252679800689,\n        \"min\": 0.0026908355879058,\n        \"max\": 0.0057292299833699,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          0.004104422304307,\n          0.0035121457002108,\n          0.0042758224818962\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Occupancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv(\"occupancy_detection.csv\")\n",
        "df_amostra = df.sample(n = 100, random_state=10)\n",
        "df_amostra.dropna(inplace=True)\n",
        "df = df_amostra.reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xWfDYyj-oqo"
      },
      "source": [
        "Nas células a seguir, vamos separar os dados em treino, validação e teste. Utilizaremos o `MaxAbsScaler` para manter os dados entre [-1,1], conservando seu formato principal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0AFzoIjkFbjS"
      },
      "outputs": [],
      "source": [
        "FEATURES = [\"Temperature\", \"Light\", \"CO2\", \"HumidityRatio\"]\n",
        "TARGET = [\"Occupancy\"]\n",
        "SEED = 10\n",
        "\n",
        "X = df[FEATURES].values\n",
        "y = df[TARGET].values\n",
        "\n",
        "# divide em treino e teste/validação\n",
        "X_train, X_tv, y_train, y_tv = train_test_split(X, y, test_size=0.4, random_state=SEED)\n",
        "\n",
        "# divide em teste e validação os valores em X_tv e y_tv\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_tv, y_tv, test_size=0.5, random_state=SEED)\n",
        "\n",
        "# normaliza os dados de entrada da rede\n",
        "scaler = MaxAbsScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_val_norm = scaler.transform(X_val)\n",
        "X_test_norm = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento da rede neural - dados normalizados"
      ],
      "metadata": {
        "id": "cWX5SN-wm12g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feita a normalização pelo máximo, demos início ao treinamento da rede neural. A arquitetura escolhida contém duas camadas ocultas, em que a primeira possui 3 neurônios e a segunda, 2."
      ],
      "metadata": {
        "id": "VuVAgohxm5TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_DADOS_DE_ENTRADA = len(FEATURES)\n",
        "NUM_DADOS_DE_SAIDA = 1\n",
        "CAMADAS_OCULTAS = [3, 2]\n",
        "\n",
        "arquitetura_da_rede = CAMADAS_OCULTAS + [NUM_DADOS_DE_SAIDA]\n",
        "\n",
        "minha_mlp = MLP_classificadora(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede)"
      ],
      "metadata": {
        "id": "h0TPFL0gpsw0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O treinamento foi realizado por 20 épocas, seguindo uma taxa de aprendizado de 0.01. Como se trata de um problema de classificação, a função de perda utilizada foi a entropia cruzada. Sendo $L_{nll}$ a função de perda, temos:\n",
        "\n",
        "$$L_{nll}(previsto, verdadeiro) = -(verdadeiro \\cdot \\log(previsto) + (1 - verdadeiro) \\cdot \\log(1 - previsto))$$\n",
        "\n",
        "Segue, abaixo, o treinamento:"
      ],
      "metadata": {
        "id": "XyI1eMvBvjjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCAS = 40\n",
        "TAXA_DE_APRENDIZADO = 0.001\n",
        "losses_treino = []\n",
        "losses_val = []\n",
        "\n",
        "for epoca in range(NUM_EPOCAS):\n",
        "\n",
        "      # forward pass\n",
        "      y_pred = []\n",
        "      y_pred_val = []\n",
        "\n",
        "      for exemplo in X_train_norm:\n",
        "          previsao = minha_mlp(exemplo)\n",
        "          y_pred.append(previsao)\n",
        "\n",
        "      for exemplo in X_val_norm:\n",
        "          previsao = minha_mlp(exemplo)\n",
        "          y_pred_val.append(previsao)\n",
        "\n",
        "      # loss pred e val\n",
        "      erros = []\n",
        "      for yt, yp in zip(y_train, y_pred):\n",
        "          yt = Value(yt)\n",
        "          nll = -(yt * (yp + tol).log() + (1 - yt + tol) * (1 - yp + tol).log())\n",
        "          erros.append(nll)\n",
        "\n",
        "      loss = sum(erros) / len(erros)\n",
        "      losses_treino.append(loss.data)\n",
        "\n",
        "      erro_val = []\n",
        "      for yt, yp in zip(y_val, y_pred_val):\n",
        "          yt = Value(yt)\n",
        "          nll = -(yt * (yp + tol).log() + (1 - yt) * (1 - yp + tol).log())\n",
        "          erro_val.append(nll)\n",
        "\n",
        "      loss_val = sum(erro_val) / len(erro_val)\n",
        "      losses_val.append(loss_val.data)\n",
        "\n",
        "    # zero grad\n",
        "      parametros_antes = minha_mlp.parametros()\n",
        "      for p in minha_mlp.parametros():\n",
        "          p.grad = 0\n",
        "\n",
        "    # backpropagation\n",
        "      loss.propagate_all()\n",
        "\n",
        "    # atualiza parâmetros\n",
        "      for p in minha_mlp.parametros():\n",
        "          p.data = p.data - p.grad * TAXA_DE_APRENDIZADO\n",
        "\n",
        "      # mostra resultado (opcional)\n",
        "      if epoca % 10 == 0:\n",
        "          print(epoca, \"loss_treino:\", loss.data, \"loss_val\", loss_val.data)"
      ],
      "metadata": {
        "id": "8lRJnfQysIFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9877626d-c817-496c-86cd-d47a109fd497"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss_treino: [0.78560027] loss_val [0.77131528]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-7f5a2bce6bf2>:135: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  data = math.exp(self.data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loss_treino: [2.18677185] loss_val [2.41706467]\n",
            "20 loss_treino: [2.18677185] loss_val [2.41706467]\n",
            "30 loss_treino: [2.18677185] loss_val [2.41706467]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi possível perceber que a perda chegou a um platô, apesar da taxa de aprendizado estar bem baixa. Vamos verificar a acurácia do modelo."
      ],
      "metadata": {
        "id": "AmVpbRUBKsqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "for exemplo in X_test_norm:\n",
        "    previsao = minha_mlp(exemplo)\n",
        "    if previsao > 0.5:\n",
        "        y_pred.append(1)\n",
        "    else:\n",
        "      y_pred.append(0)\n",
        "\n",
        "correct = 0\n",
        "for pred, true in zip(y_pred, y_test):\n",
        "    if pred == true:\n",
        "      correct += 1\n",
        "\n",
        "print('Acurácia:', correct * 100 / len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xABuJhzLNxlx",
        "outputId": "d8909cc7-984c-4b4d-a7a8-ba63f297a735"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 80.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-7f5a2bce6bf2>:135: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  data = math.exp(self.data)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A acurácia parece impressionante! Vamos verificar frente a um modelo baseline, que prediz apenas os valores que mais aparecem nos dados:"
      ],
      "metadata": {
        "id": "4UNpdRirPhMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if sum(y_test) / len(y_test) > 0.5:\n",
        "  baseline = [1] * len(y_test)\n",
        "else:\n",
        "  baseline = [0] * len(y_test)\n",
        "\n",
        "correct = 0\n",
        "for pred, true in zip(baseline, y_test):\n",
        "    if pred == true:\n",
        "      correct += 1\n",
        "\n",
        "print('Acurácia:', correct * 100 / len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS9YBBoxPtWV",
        "outputId": "9de256ff-939c-46a3-a09a-43ac1bf8cd6e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 80.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estava muito bom para ser verdade... Nosso modelo performa tão bem quanto um modelo baseline."
      ],
      "metadata": {
        "id": "jqJlZFxiQYoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusões:**\n",
        "\n",
        "Nessa tarefa, foi possível compreender o que é necessário modificar para transformar uma rede neural de classificação, modificando a saída para uma função que force os resultados para se manterem entre 0 e 1 e aplicando a função de perda NLL. Nossa rede neural não foi bem sucedida em compreender os dados reais, mas foi possível usar de conhecimentos prévios para afirmar, categoricamente, que ela é ruim."
      ],
      "metadata": {
        "id": "mab3DiHRNzgQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}